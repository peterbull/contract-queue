{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "backend_path = '../backend'\n",
    "if backend_path not in sys.path:\n",
    "        sys.path.append(backend_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, select, values, update, and_, exists\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from dotenv import load_dotenv\n",
    "from app.models.models import Notice, ResourceLink\n",
    "from app.models.schema import NoticeBase, ResourceLinkBase\n",
    "import pendulum\n",
    "import tempfile\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import json\n",
    "import datetime\n",
    "from openai import OpenAI\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATABASE_URL = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "selected_date = pendulum.now(\"utc\").subtract(days=1).strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240312:080016'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pendulum.now().strftime(\"%Y%m%d:%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as db:\n",
    "    subquery = (\n",
    "        select(ResourceLink.notice_id).\n",
    "        where(and_(ResourceLink.notice_id == Notice.id, ResourceLink.text.isnot(None)))\n",
    "    )\n",
    "    stmt = (\n",
    "        select(Notice).where(\n",
    "            and_(Notice.postedDate == selected_date,\n",
    "            (exists(subquery))\n",
    "                 )\n",
    "        )\n",
    "    )\n",
    "    results = db.execute(stmt).scalars().all()\n",
    "    results_dict = [NoticeBase.model_validate(result).dict() for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with SessionLocal() as session:\n",
    "    subquery = (\n",
    "        select(ResourceLink.notice_id).\n",
    "        where(and_(ResourceLink.notice_id == Notice.id, ResourceLink.text.isnot(None)))\n",
    "    )\n",
    "    stmt = (\n",
    "        select(Notice).\n",
    "        where(exists(subquery))\n",
    "    )\n",
    "    results = session.execute(stmt).scalars().all()\n",
    "    result_dict = [NoticeBase.model_validate(result).dict() for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_in_corpus(input:str, encoding_name: str = \"gpt-3.5-turbo-0125\") -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(input))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in result_dict:\n",
    "#     print(f\"{item['title']}\")\n",
    "#     for resource_link in item['resource_links']:\n",
    "#         print(f\">>>{num_tokens_in_corpus(resource_link['text'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_rfp = result_dict[0]['resource_links'][0]['text']\n",
    "longer_rfp = result_dict[0]['resource_links'][1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885, 23418)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_in_corpus(shorter_rfp), num_tokens_in_corpus(longer_rfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.069"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(23000 / 1000000) * 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime.datetime):\n",
    "            return obj.isoformat()\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/example_resource.json', 'w') as f:\n",
    "#     json.dump(result_dict[0], f, cls=DateTimeEncoder, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/example_resource.json', 'r') as f:\n",
    "    notice = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " res = client.chat.completions.create(model=\"gpt-3.5-turbo-0125\", messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a highly skilled AI trained to analyze text and summarize very succinctly.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The dog jumped over the big log that was laying in the forest. Yes the dog jumped. It jumped over the log. The log that was big. Big the log was. And the dog did jump over it. This all happened in the forest.\",\n",
    "    },\n",
    "    # {\n",
    "    #     \"role\": \"assistant\",\n",
    "    #     \"content\": \"My summary of the text is:\"\n",
    "    # }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=11, prompt_tokens=78, total_tokens=89)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_text_summarization(text: str, model: str = 'gpt-3.5-turbo-0125'):\n",
    "    client = OpenAI()\n",
    "    model = model\n",
    "    current_time = pendulum.now().strftime(\"%Y%m%d:%H%M%S\")\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a highly skilled AI trained to analyze text and summarize it very succinctly.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Please distill this text into it's most important parts for determining a good fit for a contractor or business that may want to provide a bid for the work. A good fit is one in which the contractor or business specializes in the requested services, and can provide those services at the correct scale. Please take all of these factors into account and return a detailed summary of no more than 7 sentences.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{text}\",\n",
    "    },\n",
    "    ]\n",
    "    res = client.chat.completions.create(model=model, messages=messages)\n",
    "    completion_tokens = res.usage.completion_tokens\n",
    "    prompt_tokens = res.usage.prompt_tokens\n",
    "    total_tokens = res.usage.total_tokens\n",
    "    data = {\n",
    "        \"Model\": model,\n",
    "        \"Completion Tokens\": completion_tokens,\n",
    "        \"Prompt Tokens\": prompt_tokens,\n",
    "        \"Total Tokens\": total_tokens,\n",
    "        \"Prompt\": messages,\n",
    "        \"Response\": res.choices[0].message.content,\n",
    "    }\n",
    "    with open(f\"./completions/{current_time}-{model}.json\", \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_content = \"The dog jumped over the big log that was laying in the forest. Yes the dog jumped. It jumped over the log. The log that was big. Big the log was. And the dog did jump over it. This all happened in the forest.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_summarization(test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The RFQ is issued by USGS National Acquisition Branch and requires firm-fixed pricing for a Field spectroradiometer. The delivery is FOB destination to USGS LRS in Reston, VA. Quotations are due by 03/19/2024. The RFQ clarifies that submitted quotations are not offers and do not compel the Government to incur any costs. Potential bidders need to provide discounted pricing, and any attached representations and certifications must be completed. Contact for queries is Contracting Officer Brian Baker.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_text_summarization(shorter_rfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick truncate the text length to fit the gpt-3.5 context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_summarization(longer_rfp[:(round(len(longer_rfp)/2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<anthropic.Anthropic at 0x7f162b0cb8e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-3-sonnet-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    \n",
    "    system=\"Respond only in Spanish.\",  # <-- system prompt\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, Claude!\"}],  # <-- user prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_015oxnM9WgBrSJAss2iPHnf3', content=[ContentBlock(text='¡Hola! Es un placer saludarte. Responderé en español como me lo has pedido.', type='text')], model='claude-3-sonnet-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=17, output_tokens=31))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=17, output_tokens=31)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_text_summarization(text: str, max_tokens: int = 1000, temperature: float = 0.0, model: str = 'claude-3-sonnet-20240229'):\n",
    "    client = anthropic.Anthropic()\n",
    "    model = model\n",
    "    current_time = pendulum.now().strftime(\"%Y%m%d:%H%M%S\")\n",
    "    max_tokens = max_tokens\n",
    "    temperature = temperature\n",
    "    system = \"You are a highly skilled AI trained to analyze text and summarize it very succinctly.\"\n",
    "    messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Please distill this text into its most important parts for determining a good fit for a contractor or business that may want to provide a bid for the work. A good fit is one in which the contractor or business specializes in the requested services, and can provide those services at the correct scale. Please take all of these factors into account and return a detailed summary of no more than 20 sentences: {text}\"\n",
    "    },\n",
    "    ]\n",
    "    res = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        system=system,\n",
    "        messages=messages)\n",
    "    completion_tokens = res.usage.output_tokens\n",
    "    prompt_tokens = res.usage.input_tokens\n",
    "    total_tokens = completion_tokens + prompt_tokens\n",
    "    data = {\n",
    "        \"Model\": model,\n",
    "        \"Completion Tokens\": completion_tokens,\n",
    "        \"Prompt Tokens\": prompt_tokens,\n",
    "        \"Total Tokens\": total_tokens,\n",
    "        \"Prompt\": messages,\n",
    "        \"Temperature\": temperature,\n",
    "        \"Max_Tokens\": max_tokens,\n",
    "        \"Response\": res.content[0].text,\n",
    "    }\n",
    "    with open(f\"./completions/{current_time}-{model}.json\", \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    return res.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a detailed summary of the most important parts of the text for determining a good fit for a contractor or business to provide a bid, in no more than 20 sentences:\\n\\n1. This is a Request for Quotation (RFQ) issued by the USGS National Acquisition Branch for a field spectroradiometer. \\n\\n2. It is not a small business set-aside.\\n\\n3. Quotes are due by 1:00 PM Eastern Time on March 19, 2024.\\n\\n4. The required item is one (1) field spectroradiometer.\\n\\n5. Functional and technical requirements, as well as applicable clauses, are provided in Attachment A.\\n\\n6. Contractors should provide firm-fixed discounted pricing for the field spectroradiometer.\\n\\n7. Questions should be directed to the Contracting Officer, Brian Baker, at bfbaker@usgs.gov.\\n\\n8. Delivery is required within 60 days after award.\\n\\n9. Delivery is FOB Destination to USGS LRS, 12201 Sunrise Valley Dr. MS 517, Reston, VA 20192-0002.\\n\\n10. Contractors must complete any attached representations and certifications.\\n\\n11. Contractors should indicate any prompt payment discounts offered.\\n\\n12. To be a good fit, a contractor should specialize in providing field spectroradiometers that meet the stated requirements.\\n\\n13. The contractor should have the capability to deliver the quantity required within the stated timeframe.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_text_summarization(shorter_rfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claude_text_summarization(longer_rfp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
