{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "backend_path = '../backend'\n",
    "if backend_path not in sys.path:\n",
    "        sys.path.append(backend_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**- [Download all attachments as zip](https://open.gsa.gov/api/opportunities-api/#download-all-attachments-as-zip-for-an-opportunity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine, select, values, update, and_, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from dotenv import load_dotenv\n",
    "from app.models.models import Notice, ResourceLink\n",
    "from app.models.schema import NoticeBase, ResourceLinkBase\n",
    "import pendulum\n",
    "import tempfile\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATABASE_URL = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "selected_date = pendulum.now(\"utc\").subtract(days=1).strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dicts of opportunity listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as session:\n",
    "    stmt = (\n",
    "        select(Notice).where(Notice.postedDate == selected_date) \n",
    "        \n",
    "    )\n",
    "    results = session.execute(stmt).scalars().all()\n",
    "    opportunities = [NoticeBase.model_validate(result).dict() for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities = opportunities[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_link = opportunities[2].get(\"resource_links\")[0].get(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://sam.gov/api/prod/opps/v3/opportunities/resources/files/6d8ef216b5194dbcb634ff8176133d95/download?api_key=null&token='"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(ex_link)\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = res.headers['Content-Disposition'].split('filename=')[1].strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SP060424R0411+MSP-ARS+AMD+0001.docx'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "    tmp.write(res.content)\n",
    "    temp_path = tmp.name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpziqby2gd'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpziqby2gd'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052252"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_file_size = os.path.getsize(temp_path)\n",
    "temp_file_size / 1000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below from **[srt-fbo-scraper](https://github.com/GSA/srt-fbo-scraper/blob/4e61da5bb518c572f5e45bbe849df60520c4abad/src/fbo_scraper/get_doc_text.py)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from zipfile import BadZipfile\n",
    "import re\n",
    "\n",
    "import textract\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_doc_text(file_name, rm=True):\n",
    "    \"\"\"Textract a doc given its path\n",
    "\n",
    "    Arguments:\n",
    "        file_name {str} -- path to a doc\n",
    "    \"\"\"\n",
    "    try:\n",
    "        b_text = None\n",
    "        try:\n",
    "            b_text = textract.process(file_name, encoding=\"utf-8\", errors=\"ignore\")\n",
    "        # ShellError with antiword occurs when an rtf is saved with a doc extension\n",
    "        except textract.exceptions.ShellError as e:\n",
    "            err_message = str(e)\n",
    "            try:\n",
    "                if \"antiword\" in err_message and file_name.endswith(\".doc\"):\n",
    "                    new_name = file_name.replace(\".doc\", \".rtf\")\n",
    "                    os.rename(file_name, new_name)\n",
    "                    b_text = textract.process(\n",
    "                        new_name, encoding=\"utf-8\", errors=\"ignore\"\n",
    "                    )\n",
    "            except textract.exceptions.ShellError as ex:\n",
    "                logger.error(\n",
    "                    \"Error extracting text from a DOC file. Check that all dependencies of textract are installed.\\n{}\".format(\n",
    "                        ex\n",
    "                    )\n",
    "                )\n",
    "        except textract.exceptions.MissingFileError as e:\n",
    "            b_text = None\n",
    "            logger.error(\n",
    "                f\"Couldn't textract {file_name} since the file couldn't be found: {e}\",\n",
    "                exc_info=True,\n",
    "            )\n",
    "        # This can be raised when a pdf is incorrectly saved as a .docx (GH183)\n",
    "        except BadZipfile as e:\n",
    "            if file_name.endswith(\".docx\"):\n",
    "                new_name = file_name.replace(\".docx\", \".pdf\")\n",
    "                os.rename(file_name, new_name)\n",
    "                b_text = textract.process(\n",
    "                    new_name, encoding=\"utf-8\", method=\"pdftotext\", errors=\"ignore\"\n",
    "                )\n",
    "            else:\n",
    "                b_text = None\n",
    "                logger.warning(\n",
    "                    f\"Exception occurred textracting {file_name}: {e}\", exc_info=True\n",
    "                )\n",
    "        # TypeError is raised when None is passed to str.decode()\n",
    "        # This happens when textract can't extract text from scanned documents\n",
    "        except TypeError:\n",
    "            b_text = None\n",
    "        except Exception as e:\n",
    "            if re.match(\"^(.*) file; not supported\", str(e)):\n",
    "                logger.warning(f\"'{file_name}' is type {str(e)}\")\n",
    "            elif re.match(\"^The filename extension .zip is not yet supported\", str(e)):\n",
    "                logger.warning(\n",
    "                    f\"'{file_name}' is type zip and not supported by textract\"\n",
    "                )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"Exception occurred textracting {file_name}: {e}\", exc_info=True\n",
    "                )\n",
    "            b_text = None\n",
    "        text = b_text.decode(\"utf8\", errors=\"ignore\").strip() if b_text else \"\"\n",
    "        if rm:\n",
    "            try:\n",
    "                os.remove(file_name)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"{e}Unable to remove {file_name}\", exc_info=True)\n",
    "            finally:\n",
    "                return text\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"Error uncaught when trying to parse file {file_name}. Giving up and returning an empty string. {e}\",\n",
    "            exc_info=True,\n",
    "        )\n",
    "        text = \"\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpziqby2gd'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception occurred textracting /tmp/tmpziqby2gd: 'utf-8' codec can't decode byte 0xdf in position 15: invalid continuation byte\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_60462/1117094731.py\", line 20, in get_doc_text\n",
      "    b_text = textract.process(file_name, encoding=\"utf-8\", errors=\"ignore\")\n",
      "  File \"/home/peter-legion-wsl2/peter-projects/contract-queue/.venv/lib/python3.10/site-packages/textract/parsers/__init__.py\", line 79, in process\n",
      "    return parser.process(filename, input_encoding, output_encoding, **kwargs)\n",
      "  File \"/home/peter-legion-wsl2/peter-projects/contract-queue/.venv/lib/python3.10/site-packages/textract/parsers/utils.py\", line 46, in process\n",
      "    byte_string = self.extract(filename, **kwargs)\n",
      "  File \"/home/peter-legion-wsl2/peter-projects/contract-queue/.venv/lib/python3.10/site-packages/textract/parsers/txt_parser.py\", line 9, in extract\n",
      "    return stream.read()\n",
      "  File \"/usr/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xdf in position 15: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "text = get_doc_text(temp_path, rm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bytes = text.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_bytes) / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510.00000000000006"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".17 * 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(res):\n",
    "    file_name = res.headers['Content-Disposition'].split('filename=')[1].strip('\"')\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as session:\n",
    "    stmt = select(ResourceLink)\n",
    "    results = session.execute(stmt).scalars().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as session:\n",
    "    stmt = (\n",
    "        select(ResourceLink).where(ResourceLink.text.is_(None))    \n",
    "    )\n",
    "    results = session.execute(stmt).scalars().all()\n",
    "    resource_links = [ResourceLinkBase.model_validate(result).dict() for result in results]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as session:\n",
    "    subquery = (\n",
    "        select(ResourceLink.notice_id).\n",
    "        distinct()\n",
    "    )\n",
    "    stmt = (\n",
    "        select(ResourceLink).\n",
    "        where(and_(ResourceLink.notice_id.in_(subquery),\n",
    "        ResourceLink.text.is_(None) \n",
    "        )).limit(20)\n",
    "    )\n",
    "    results = session.execute(stmt).scalars().all()\n",
    "    resource_links = [ResourceLinkBase.model_validate(result).dict() for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resource_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(resource_links[1].get(\"url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as session:\n",
    "    stmt = (\n",
    "        select(Notice).where(\n",
    "            and_(\n",
    "                Notice.id == ResourceLink.notice_id,\n",
    "                ResourceLink.text.is_(None)\n",
    "                )\n",
    "        )\n",
    "    )\n",
    "    results = session.execute(stmt).scalars().all()\n",
    "    result_dict = [NoticeBase.model_validate(result).dict() for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A22.W912EK24B0008+-+CLINTON+PL84-99+-+FINAL+PLAN+SET.pdf'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_name(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A22.W912EK24B0008+-+CLINTON+PL84-99+-+FINAL+PLAN+SET.pdf'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_name(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "    tmp.write(res.content)\n",
    "    temp_path = tmp.name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpoeunh07a'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception occurred textracting /tmp/tmpoeunh07a: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_60462/1117094731.py\", line 20, in get_doc_text\n",
      "    b_text = textract.process(file_name, encoding=\"utf-8\", errors=\"ignore\")\n",
      "  File \"/home/peter-legion-wsl2/peter-projects/contract-queue/.venv/lib/python3.10/site-packages/textract/parsers/__init__.py\", line 79, in process\n",
      "    return parser.process(filename, input_encoding, output_encoding, **kwargs)\n",
      "  File \"/home/peter-legion-wsl2/peter-projects/contract-queue/.venv/lib/python3.10/site-packages/textract/parsers/utils.py\", line 46, in process\n",
      "    byte_string = self.extract(filename, **kwargs)\n",
      "  File \"/home/peter-legion-wsl2/peter-projects/contract-queue/.venv/lib/python3.10/site-packages/textract/parsers/txt_parser.py\", line 9, in extract\n",
      "    return stream.read()\n",
      "  File \"/usr/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "text = get_doc_text(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a batch of 20 to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A22.W912EK24B0008+-+CLINTON+PL84-99+-+FINAL+PLAN+SET_AMND+0001_REVISED+C-301_11MAR2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:46,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A22.W912EK24B0008+-+CLINTON+PL84-99+-+FINAL+PLAN+SET.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:16<02:50,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A22.W912EK24B0008+-+CLINTON+PL84-99+-+FINAL+SOLICITATION+W+SPECS_REVISED+11MAR2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:29<03:09, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A22.W912EK24B0008+-+CLINTON+PL84-99+-+AMENDMENT+0001_11MAR2024.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:30<01:52,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WD+2015-5631+Rev+20+dated+12-26-2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:32<00:48,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36C26124Q0411_1.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:33<00:33,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36C25224Q0240_1.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:33<00:22,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36C25224Q0240+0002.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:34<00:15,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36C25224Q0240+0001.docx\n",
      "Solicitation-+Global+Fund+Liaison_Resolicit_Final_.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:36<00:16,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMENDMENT+1+12444624Q0034.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:37<00:09,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attachment+B+CSE+SOW+and+Specifications+WRD+2024.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:38<00:06,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attachment+C+Exhibits+1+thru+6+WRD+2024.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:38<00:04,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attachment+D+Submission+Package.docx\n",
      "Attachment+E+List+of+stands+by+bid+Item.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:40<00:03,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attachment+G+81-1253.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:41<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attachment+A+schedule+of+items+Drum+East+FY24+CSE.docx\n",
      "12444624Q0034+combined+doc.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:43<00:02,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attachment+F+Drum+East+FY24+all+maps.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:49<00:02,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WD+2015-5405+Rev+21+Date+12-26-2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:53<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "for resource_link in tqdm(resource_links):\n",
    "    res = requests.get(resource_link.get(\"url\"))\n",
    "    file_name = get_file_name(res)\n",
    "    print(file_name)\n",
    "    prefix, suffix = os.path.splitext(get_file_name(res))\n",
    "    suffix = '.' + suffix\n",
    "    with tempfile.NamedTemporaryFile(prefix=prefix, suffix=suffix, delete=False) as tmp:\n",
    "        tmp.write(res.content)\n",
    "        tmp.flush()\n",
    "        temp_path = tmp.name\n",
    "        text = get_doc_text(temp_path, rm=True)\n",
    "        with SessionLocal() as session:\n",
    "            if text:\n",
    "                # clean null characters before committing\n",
    "                text = text.replace(\"\\x00\", \"\\uFFFD\")\n",
    "                stmt = (\n",
    "                    update(ResourceLink).\n",
    "                    where(ResourceLink.id == resource_link['id']).\n",
    "                    values(text=text)\n",
    "                )\n",
    "                session.execute(stmt)\n",
    "                session.commit()\n",
    "            else:\n",
    "                stmt = (\n",
    "                    update(ResourceLink).\n",
    "                    where(ResourceLink.id == resource_link['id']).\n",
    "                    values(text=\"unparsable\")\n",
    "                )\n",
    "                session.execute(stmt)\n",
    "                session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Todo:** Add error handling for filename too long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
