{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "backend_path = '../backend'\n",
    "if backend_path not in sys.path:\n",
    "        sys.path.append(backend_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, select, values, update, and_, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from dotenv import load_dotenv\n",
    "from app.models.models import Notice, ResourceLink\n",
    "from app.models.schema import NoticeBase, ResourceLinkBase\n",
    "import pendulum\n",
    "import tempfile\n",
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import os\n",
    "from zipfile import BadZipfile\n",
    "import re\n",
    "\n",
    "import textract\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATABASE_URL = \"postgresql+psycopg2://airflow:airflow@localhost:5432/airflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "selected_date = pendulum.now(\"utc\").subtract(days=1).strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_text(file_name, rm=True):\n",
    "    \"\"\"Textract a doc given its path\n",
    "\n",
    "    Arguments:\n",
    "        file_name {str} -- path to a doc\n",
    "    \"\"\"\n",
    "    try:\n",
    "        b_text = None\n",
    "        try:\n",
    "            b_text = textract.process(file_name, encoding=\"utf-8\", errors=\"ignore\")\n",
    "        # ShellError with antiword occurs when an rtf is saved with a doc extension\n",
    "        except textract.exceptions.ShellError as e:\n",
    "            err_message = str(e)\n",
    "            try:\n",
    "                if \"antiword\" in err_message and file_name.endswith(\".doc\"):\n",
    "                    new_name = file_name.replace(\".doc\", \".rtf\")\n",
    "                    os.rename(file_name, new_name)\n",
    "                    b_text = textract.process(\n",
    "                        new_name, encoding=\"utf-8\", errors=\"ignore\"\n",
    "                    )\n",
    "            except textract.exceptions.ShellError as ex:\n",
    "                logger.error(\n",
    "                    \"Error extracting text from a DOC file. Check that all dependencies of textract are installed.\\n{}\".format(\n",
    "                        ex\n",
    "                    )\n",
    "                )\n",
    "        except textract.exceptions.MissingFileError as e:\n",
    "            b_text = None\n",
    "            logger.error(\n",
    "                f\"Couldn't textract {file_name} since the file couldn't be found: {e}\",\n",
    "                exc_info=True,\n",
    "            )\n",
    "        # This can be raised when a pdf is incorrectly saved as a .docx (GH183)\n",
    "        except BadZipfile as e:\n",
    "            if file_name.endswith(\".docx\"):\n",
    "                new_name = file_name.replace(\".docx\", \".pdf\")\n",
    "                os.rename(file_name, new_name)\n",
    "                b_text = textract.process(\n",
    "                    new_name, encoding=\"utf-8\", method=\"pdftotext\", errors=\"ignore\"\n",
    "                )\n",
    "            else:\n",
    "                b_text = None\n",
    "                logger.warning(\n",
    "                    f\"Exception occurred textracting {file_name}: {e}\", exc_info=True\n",
    "                )\n",
    "        # TypeError is raised when None is passed to str.decode()\n",
    "        # This happens when textract can't extract text from scanned documents\n",
    "        except TypeError:\n",
    "            b_text = None\n",
    "        except Exception as e:\n",
    "            if re.match(\"^(.*) file; not supported\", str(e)):\n",
    "                logger.warning(f\"'{file_name}' is type {str(e)}\")\n",
    "            elif re.match(\"^The filename extension .zip is not yet supported\", str(e)):\n",
    "                logger.warning(\n",
    "                    f\"'{file_name}' is type zip and not supported by textract\"\n",
    "                )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"Exception occurred textracting {file_name}: {e}\", exc_info=True\n",
    "                )\n",
    "            b_text = None\n",
    "        text = b_text.decode(\"utf8\", errors=\"ignore\").strip() if b_text else \"\"\n",
    "        if rm:\n",
    "            try:\n",
    "                os.remove(file_name)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"{e}Unable to remove {file_name}\", exc_info=True)\n",
    "            finally:\n",
    "                return text\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"Error uncaught when trying to parse file {file_name}. Giving up and returning an empty string. {e}\",\n",
    "            exc_info=True,\n",
    "        )\n",
    "        text = \"\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as session:\n",
    "    subquery = (\n",
    "        select(ResourceLink.notice_id).\n",
    "        distinct()\n",
    "    )\n",
    "    stmt = (\n",
    "        select(ResourceLink).\n",
    "        where(and_(ResourceLink.notice_id.in_(subquery),\n",
    "        ResourceLink.text.is_(None) \n",
    "        )).limit(20)\n",
    "    )\n",
    "    results = session.execute(stmt).scalars().all()\n",
    "    resource_links = [ResourceLinkBase.model_validate(result).dict() for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 53,\n",
       "  'url': 'https://sam.gov/api/prod/opps/v3/opportunities/resources/files/979dabe2bcaa4019b902e4397f5c9a59/download?api_key=null&token=',\n",
       "  'text': None},\n",
       " {'id': 54,\n",
       "  'url': 'https://sam.gov/api/prod/opps/v3/opportunities/resources/files/cefae3bd5418491f9a2a789a4703ca9c/download?api_key=null&token=',\n",
       "  'text': None}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_links[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(resource_links[0].get(\"url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x-amz-id-2': 'bmx6QDaZkt6NoKSR+EYS5z5+4z5ZFqqTjph1ukYai7UVQMaDsMhD2VTStFe1kAxBHKmaVvBafc+Uu1QXFPq43IXEsLG7qY6c00efLuouO7U=', 'x-amz-request-id': 'SBY23N6N6CXK05Q7', 'Date': 'Wed, 13 Mar 2024 12:47:18 GMT', 'Last-Modified': 'Mon, 11 Mar 2024 15:20:21 GMT', 'ETag': '\"1aa2b353a8d198277724548e970c907f\"', 'x-amz-tagging-count': '2', 'x-amz-server-side-encryption': 'AES256', 'x-amz-version-id': 'Veua3.BTQcOnKkRcnL4keUaJ6Kkxq2sv', 'Content-Disposition': 'attachment; filename=1240LP24Q0021-+Laramie+RD+Trash+Collection.pdf', 'Accept-Ranges': 'bytes', 'Content-Type': 'application/octet-stream', 'Server': 'AmazonS3', 'Content-Length': '901388'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a redirect response to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x-amz-request-id': '3ZRGTB4KG6TTT7HZ', 'x-amz-id-2': '26jWc1VZjw6/lFc+8OpSYdM/qWJwTWhsGE/Mtet/icDMQD9owi7/qYntUBkQzTb9xad6TKlhurU=', 'Content-Type': 'application/xml', 'Date': 'Wed, 13 Mar 2024 12:55:54 GMT', 'Server': 'AmazonS3'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = res.headers['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.head(location)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.head(resource_links[0].get(\"url\"), allow_redirects=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the entire file will have to be streamed to check for content-length. Will look into alternate methods of optimization after a baseline of the application logic is up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
